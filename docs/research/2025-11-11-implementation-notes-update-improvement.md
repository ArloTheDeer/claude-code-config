# 實作備註更新機制改善研究

## 執行摘要

本研究針對 `/process-task-list` slash command 中 AI 助手更新實作備註的問題進行深入分析。研究發現當前機制存在兩個核心問題：**照預期完成的任務寫了過多備註**，以及**偏離計畫的關鍵調整卻沒有被記錄**。

經過對 prompt engineering 最佳實踐、Claude AI 長文本召回機制、以及現有指令結構的全面分析，我們識別出問題的根本原因在於：

1. **時機點設計缺陷**：要求在任務完成後才回顧整個對話歷程，但長對話會導致 AI 無法有效識別關鍵偏離
2. **判斷標準模糊**：「與原始計畫的重大偏離」這樣的描述缺乏具體的判斷準則
3. **缺乏結構化引導**：沒有提供明確的資訊萃取框架，導致 AI 難以區分「值得記錄」和「不值得記錄」的內容

研究提出三個改善方案，建議採用**方案二：邊做邊記錄 + 結構化引導**，在任務執行過程中即時記錄關鍵資訊，搭配清晰的判斷準則和實例，既能解決長對話召回問題，又能保持工作流程的流暢性。

## 背景與脈絡

claude-code-config 專案實施了一套三步驟規範驅動的開發工作流程：需求澄清 → 實作規劃 → 任務執行。在第三步「任務執行」階段，`/process-task-list` slash command 引導 AI 助手逐一完成 implementation.md 中的任務。為了保留實作過程中的重要上下文，每個任務包含一個「實作備註」區塊，用於記錄：

- 與原始計畫的重大偏離和原因
- 關鍵的技術決策
- 遇到的技術障礙和解決方案
- 需要後續任務注意的依賴或前置條件
- 如照預期完成，可標註「照預期開發」或留空

然而，在實際使用中發現 AI 助手並未按照期望填寫實作備註。具體表現為兩個問題：

1. **過度記錄問題**：按照預期實作的任務寫了過多細節，這些資訊本應從原任務敘述中就能獲得
2. **遺漏記錄問題**：實作過程中發生的方向調整、設計錯誤修正等關鍵資訊卻沒有被記錄

這個問題的影響是深遠的。實作備註的設計初衷是作為跨對話框的知識傳遞機制，特別是在長期開發場景中（專案可能跨越多個對話框完成），缺失的實作備註會導致後續任務或驗收階段無法理解「為什麼這裡要這樣做」、「遇到了什麼問題」等關鍵上下文。

更重要的是，當驗收階段發現設計問題時，如果實作備註中沒有記錄當初的設計考量和調整過程，就無法有效地進行根本原因分析，也難以避免在未來犯同樣的錯誤。

## 研究問題與發現過程

### 初始問題陳述

使用者觀察到 AI 助手在使用 `/process-task-list` 執行任務時，不會認真更新實作備註。具體案例包括：

- 實作過程中發現錯誤需要改變方向，與 AI 進行較長的討論後完成實作，但任務完成時沒有記錄這個調整
- 驗收階段才發現設計錯誤，但 AI 也沒有在實作備註中記錄修正過程

使用者原本希望 AI 在「任務完成時才回顧」並填寫實作備註，但懷疑在較長對話後，AI 可能會忘記整個對話歷程的重點。

### 釐清過程

經過與使用者的深入討論，我們釐清了以下關鍵資訊：

**觸發時機**：實作備註應該在「每個任務的實作部分完成後」填寫，而不是所有任務完成後才統一填寫。

**內容期望**：主要記錄前三項（偏離、決策、障礙），照預期完成的任務應該盡可能精簡記錄，因為原本的任務敘述就足夠了。

**現有問題的具體表現**：
- AI 都有寫實作備註，但存在兩個問題
- 第一個問題：按照預期實作的寫了太多，這不是需要的
- 第二個問題：不按照預期的卻沒有寫，可能是 AI 無法完整回顧對話中遇到困難的部分

**互動模式**：當發現錯誤需要改方向時，通常會指出錯誤後又有較長的實作流程一起發生。這種調整在任務執行的各個階段都可能發生（有剛開始就錯的，也有驗收時才發現的）。

**對解決方案的開放態度**：使用者原本期望「任務完成時才回顧」，但如果這種方式行不通，「邊做邊記錄」也可以接受。這種彈性為我們提供了更多的解決方案空間。

### 問題重新定義

綜合以上資訊，我們將問題重新定義為：

**如何設計 prompt 機制，讓 AI 助手能夠在任務執行過程中或完成時，準確識別「值得記錄」的資訊（偏離、決策、障礙），同時避免在「按預期完成」的情況下過度記錄？**

這個問題的難點在於「判斷」—— AI 需要判斷什麼是「重大偏離」、什麼是「關鍵決策」、什麼是「技術障礙」，以及什麼情況屬於「照預期完成」。當前的指令敘述顯然沒有為這個判斷過程提供足夠的指導。

## 技術分析：深入理解問題

### 程式碼庫現況探索

審查 `commands/process-task-list.md` 的相關章節，我們發現當前的實作備註填寫指示位於第 102-107 行：

```markdown
- **填寫實作備註**：在「任務細節」對應任務的「實作備註」區塊中記錄：
  - 與原始計畫的重大偏離和原因
  - 關鍵的技術決策
  - 遇到的技術障礙和解決方案
  - 需要後續任務注意的依賴或前置條件
  - 如照預期完成，可標註「照預期開發」或留空
```

這個指示存在以下問題：

**判斷標準模糊**：
- 什麼是「重大偏離」？與「小調整」的界線在哪裡？
- 什麼是「關鍵的技術決策」？所有技術決策都要記錄嗎？
- 什麼程度的問題算「技術障礙」？

**缺乏對比範例**：
- 沒有提供「好的實作備註」和「不好的實作備註」的範例
- 沒有展示「照預期完成」vs「有重大偏離」的具體案例

**執行時機不明確**：
- 「完成任務後」這個描述過於簡化
- 沒有說明是在 git commit 之前還是之後
- 沒有說明如何在長對話中回顧關鍵資訊

**與完成協議的整合不清晰**：
目前的「完成協議」（第 99-117 行）列出了一系列步驟，但「填寫實作備註」只是第一步，後續還有「更新任務狀態」、「暫存變更」、「清理」、「提交」等步驟。這種結構可能會讓 AI 認為需要快速完成第一步以進行後續步驟，從而不夠仔細地填寫實作備註。

### 問題根源追蹤

基於對現有指令的分析和使用者的回饋，我們可以追溯到問題的根源：

**根源一：回顧式設計的固有限制**

當前設計要求 AI 在任務完成後回顧整個對話，識別哪些部分屬於「重大偏離」或「技術障礙」。這種設計在短對話中可能有效，但在長對話中存在以下問題：

1. **長文本召回挑戰**：雖然 Claude 支援長文本（100K+ tokens），但在實際應用中，從長對話中選擇性提取特定資訊（如「偏離點」）的準確性會隨對話長度增加而降低
2. **缺乏標記機制**：對話過程中沒有任何機制來「標記」重要時刻（如方向調整、設計變更），AI 需要完全依賴語義理解來識別
3. **時序混淆**：完成任務時，AI 的注意力可能集中在最終的程式碼正確性上，而忘記了中間的調整過程

**根源二：判斷標準的主觀性**

「重大偏離」、「關鍵決策」、「技術障礙」這些概念都具有主觀性。沒有明確的判斷準則，不同的 AI 運行實例（甚至同一實例在不同時刻）可能會有不同的理解：

1. **過度保守**：AI 可能認為所有偏離都「重大」，所有決策都「關鍵」，導致過度記錄
2. **過度寬鬆**：AI 可能認為大部分調整都是「正常的開發過程」，不值得特別記錄
3. **缺乏基準**：沒有參考標準，AI 無法校準自己的判斷

**根源三：注意力分散**

「完成協議」包含多個步驟，AI 需要在完成任務後依序執行。這種多步驟設計可能導致：

1. **認知負荷**：AI 需要同時考慮多個任務（回顧對話、更新狀態、準備提交等）
2. **優先級混淆**：可能將「快速進入下一步」視為更重要的目標
3. **質量妥協**：為了完成整個流程，可能在每個單獨步驟上投入較少的「注意力」

### 業界智慧與最佳實踐

從 prompt engineering 和 AI 系統設計的角度，業界有以下相關實踐可以參考：

**長文本召回優化技術**（Anthropic 官方指引）：

1. **Quote Extraction Method（引用提取法）**：在回答問題前，先要求 AI 提取相關引用到「草稿區」。這種技術可以改善長文本中的資訊召回準確性
2. **Contextual Examples（上下文範例）**：提供具體範例來引導 AI 的行為，比通用指示更有效
3. **XML Tags for Structure（XML 標籤結構化）**：Claude 對 XML 標籤有特別的注意力，可用來清晰分隔不同部分

**即時記錄 vs 回顧記錄**（Documentation Best Practices）：

研究顯示，在軟體開發中，「即時記錄」（logging as you go）通常比「事後回顧」（retrospective documentation）更準確：

1. **即時記錄的優勢**：減少遺忘、捕捉當下的思考過程、更容易識別重要時刻
2. **回顧記錄的優勢**：可以過濾掉不重要的細節、提供更宏觀的視角、更簡潔
3. **混合方法**：許多成功的文件化系統結合兩者—即時記錄關鍵點，完成後整理和精煉

**判斷標準的具體化**（Prompt Engineering Guidelines）：

1. **使用具體範例**：不要只說「記錄重要的決策」，而是展示什麼樣的決策是「重要的」
2. **提供對比**：展示「好的」vs「不好的」範例，幫助 AI 校準判斷
3. **使用檢查清單**：將抽象概念轉換為具體可檢查的條件
4. **量化標準**：盡可能提供可量化的標準（如「討論超過 3 輪」、「修改超過 2 次」）

**結構化 Prompt 設計**（Best Practices for Task Completion）：

1. **Single Responsibility**：每個指示應該專注於單一任務，避免認知負荷過高
2. **Clear Sequencing**：如果有多個步驟，明確說明執行順序和每個步驟的重要性
3. **Explicit Checkpoints**：在關鍵點設置明確的檢查點，確保 AI 完成後再進行下一步

## 解決方案探索與評估

基於對問題根源的分析和業界最佳實踐的研究，我們提出三個解決方案，每個方案都有不同的權衡。

### 方案一：增強回顧機制（最小改動）

**核心概念**：保持現有的「任務完成時回顧」設計，但增強回顧機制的有效性。

**具體改動**：

1. **引入 Quote Extraction（引用提取）**：在填寫實作備註前，先要求 AI 提取對話中的關鍵片段

```markdown
- **填寫實作備註**：
  1. 首先，回顧本任務的完整對話歷程，提取以下關鍵時刻的具體對話片段：
     - 發現原計畫不可行或需要調整的時刻
     - 做出重要技術選擇的討論
     - 遇到技術問題和解決的過程
  2. 基於提取的片段，在「任務細節」對應任務的「實作備註」區塊中記錄：
     - 與原始計畫的重大偏離和原因
     - 關鍵的技術決策
     - 遇到的技術障礙和解決方案
     - 需要後續任務注意的依賴或前置條件
```

2. **提供具體判斷準則**：

```markdown
**什麼需要記錄？**
- ✅ 需要記錄：
  - 原任務敘述中提到的方法行不通，改用其他方法
  - 發現設計錯誤，需要修改先前的實作
  - 遇到預期外的技術限制（如 API 不支援、效能問題）
  - 與使用者討論超過 3 輪才確定的技術方案
  - 需要告知後續任務的重要資訊（如「必須先完成 X 才能做 Y」）

- ❌ 不需記錄：
  - 按照任務敘述直接實作完成
  - 正常的除錯過程（如修正小的語法錯誤、typo）
  - 任務敘述中已經提到的實作細節
  - 常規的技術選擇（如選擇已知的資料結構、設計模式）
```

3. **提供範例對比**：

```markdown
**實作備註範例**：

【照預期完成的情況】
✅ 良好：「照預期開發」或留空
❌ 過度：「實作了 UserAuth 類別，使用 bcrypt 加密密碼，建立了三個測試案例...」
（原因：這些都在任務敘述中，不需重複）

【有重大偏離的情況】
✅ 良好：「原計畫使用 localStorage，但發現需要跨 tab 同步，改用 BroadcastChannel API。參考 MDN 文件確認瀏覽器支援度 95%+」
❌ 不足：「改用了 BroadcastChannel」
（原因：沒說明為什麼改、怎麼驗證的）
```

**評估**：

- **優點**：
  - 最小改動，與現有流程相容
  - 保持「完成後統一填寫」的設計
  - 通過具體指引和範例提高判斷準確性

- **缺點**：
  - 仍然依賴 AI 的長文本召回能力
  - 引用提取步驟會增加處理時間
  - 在極長對話中可能仍有遺漏

- **適用場景**：任務對話不會太長（< 50 輪對話），或者偏離情況相對簡單明確

### 方案二：邊做邊記錄 + 結構化引導（推薦）

**核心概念**：改變填寫時機，在任務執行過程中即時記錄關鍵資訊，同時提供結構化的引導。

**具體改動**：

1. **新增實作過程記錄指引**：

在「任務實作」章節（第 92 行之後）新增以下內容：

```markdown
- **實作過程記錄**：
  - 在任務執行過程中，遇到以下情況時，**立即**在「實作備註」區塊記錄：

    1. **方向調整**：發現原計畫不可行或需要改用其他方法時
       - 觸發條件：使用者指出錯誤、發現技術限制、原方法行不通
       - 記錄格式：`[方向調整] 原計畫 X 因 Y 原因不可行，改用 Z 方法`
       - 範例：`[方向調整] 原計畫使用 localStorage 但需跨 tab 同步，改用 BroadcastChannel API`

    2. **技術障礙**：遇到預期外的問題需要特別處理時
       - 觸發條件：API 不支援、效能瓶頸、相容性問題、需要繞過的限制
       - 記錄格式：`[技術障礙] 遇到 X 問題，因為 Y，解決方式是 Z`
       - 範例：`[技術障礙] Next.js 動態路由不支援 SSG，需使用 generateStaticParams 預生成路徑`

    3. **關鍵決策**：與使用者討論超過 3 輪才確定的技術方案
       - 觸發條件：有多個可行方案、需要權衡取捨、影響後續任務
       - 記錄格式：`[技術決策] 在 X 和 Y 方案之間選擇 Z，因為 W`
       - 範例：`[技術決策] 在 REST 和 GraphQL 之間選擇 REST，因現有後端已是 REST 且團隊更熟悉`

    4. **後續依賴**：後續任務必須知道的資訊
       - 觸發條件：建立了新的前置條件、修改了共享資源、有執行順序要求
       - 記錄格式：`[後續依賴] 後續任務需注意 X，因為 Y`
       - 範例：`[後續依賴] 後續任務需注意必須先呼叫 initAuth() 才能使用其他 auth 函數`

  - **照預期完成時**：如果整個任務執行過程都按照任務敘述順利完成，沒有觸發上述任何情況，則標註「照預期開發」
```

2. **修改完成協議中的實作備註步驟**：

將第 102-107 行修改為：

```markdown
- **檢查並完善實作備註**：
  - 檢視「實作備註」區塊，確認已記錄所有方向調整、技術障礙、關鍵決策、後續依賴
  - 如果執行過程中已經即時記錄，確認記錄完整清晰
  - 如果執行過程中沒有觸發任何需要記錄的情況，標註「照預期開發」
  - **不要**重複記錄任務敘述中已有的實作細節
```

3. **提供記錄範例對照表**：

```markdown
**實作備註品質檢查清單**：

| 情況 | ✅ 良好範例 | ❌ 避免範例 |
|------|-----------|-----------|
| 按預期完成 | 「照預期開發」 | 列出所有實作細節（這些應該在任務敘述中） |
| 方向調整 | `[方向調整] 原用 X 但因 Y 不可行改用 Z，驗證後確認可行` | `改用了另一個方法` |
| 技術障礙 | `[技術障礙] X 限制導致 Y 問題，使用 Z 繞過，測試通過` | `遇到一些問題但解決了` |
| 關鍵決策 | `[技術決策] 比較 X 和 Y，選擇 Y 因 Z 考量，權衡是 W` | `決定用 Y` |
| 後續依賴 | `[後續依賴] 新增全域 config，後續任務需引入此檔案` | `做了一些修改` |
```

**評估**：

- **優點**：
  - 解決長對話召回問題（即時記錄不依賴回顧）
  - 結構化標籤（如 `[方向調整]`）讓記錄更清晰
  - 明確的觸發條件降低判斷的主觀性
  - 提供具體範例和對照表提高執行準確性

- **缺點**：
  - 需要改變執行習慣（從「完成後」到「邊做邊記」）
  - 可能會打斷實作流程（但影響應該不大）
  - 增加了一些執行步驟

- **風險控管**：
  - 「即時記錄」可能會讓 AI 感到「被打斷」，但可以通過清晰的指引（「立即記錄」）來強化
  - 記錄過於頻繁可能導致備註過長，但通過明確的觸發條件可以控制

- **適用場景**：所有情況，特別是會有較長對話或複雜調整的任務

### 方案三：混合式記錄（最全面）

**核心概念**：結合方案一和方案二，既在過程中即時記錄，也在完成時進行回顧和精煉。

**具體改動**：

1. 保留方案二的「邊做邊記錄」機制
2. 在完成協議中增加「回顧與精煉」步驟：

```markdown
- **回顧並精煉實作備註**：
  1. 檢視執行過程中即時記錄的實作備註
  2. 評估每條記錄的必要性：
     - 保留：對後續任務或未來維護有價值的資訊
     - 移除：過於細節的技術操作、已解決的暫時性問題
  3. 整合相關記錄：
     - 如果多條記錄是關於同一個調整，合併為單一、連貫的描述
     - 確保每條記錄都有清晰的脈絡（為什麼、怎麼做、結果如何）
  4. 最終檢查：
     - 總字數控制在 200-300 字以內（除非有特殊複雜情況）
     - 每條記錄都符合格式要求（使用標籤如 `[方向調整]`）
     - 照預期完成的任務標註「照預期開發」或留空
```

3. 提供精煉範例：

```markdown
**實作備註精煉範例**：

【執行過程中的即時記錄】
```
[方向調整] localStorage 不支援跨 tab
[技術障礙] 試了 SharedWorker 但 Safari 不支援
[技術決策] 最後用 BroadcastChannel API
[後續依賴] 需要 polyfill 給舊瀏覽器
```

【完成後精煉】
```
[方向調整] 原計畫使用 localStorage，但發現需要跨 tab 同步狀態。評估 SharedWorker（Safari 不支援）和 BroadcastChannel（現代瀏覽器支援度 95%+），選擇後者並為舊瀏覽器準備 polyfill。後續任務需引入 polyfill 設定。
```
```

**評估**：

- **優點**：
  - 最全面，同時解決召回和品質問題
  - 即時記錄確保不遺漏，回顧精煉確保品質
  - 最終輸出簡潔且有價值

- **缺點**：
  - 最複雜，步驟最多
  - 增加執行時間和認知負荷
  - AI 可能在「精煉」步驟中過度編輯或反而引入錯誤

- **風險控管**：
  - 需要明確指引避免過度精煉（如「保留技術細節，只移除明顯冗餘」）
  - 需要範例展示「適度精煉」的程度

- **適用場景**：非常複雜的任務，或者對實作備註品質要求極高的專案

### 方案比較總表

| 評估維度 | 方案一：增強回顧 | 方案二：邊做邊記錄（推薦） | 方案三：混合式 |
|---------|----------------|----------------------|-------------|
| **實作複雜度** | 低（主要是指引修改） | 中（需改變執行流程） | 高（兩階段記錄） |
| **解決召回問題** | 部分（長對話仍可能遺漏） | 完全（即時記錄不依賴回顧） | 完全 |
| **解決過度記錄問題** | 是（通過範例和準則） | 是（通過明確觸發條件） | 是 |
| **對流程的影響** | 最小 | 適中（需要在執行中記錄） | 較大（需要額外精煉步驟） |
| **執行時間增加** | 少量（引用提取） | 適中（即時記錄） | 較多（記錄 + 精煉） |
| **學習曲線** | 低（AI 容易適應） | 中（需理解新流程） | 高（兩階段流程） |
| **輸出品質** | 中（依賴 AI 判斷） | 高（結構化 + 即時） | 最高（精煉過） |
| **適用場景** | 簡單任務、短對話 | 大多數情況 | 複雜任務、高品質要求 |
| **風險等級** | 低 | 中 | 中高 |

## 建議與決策指引

### 推薦方案：方案二（邊做邊記錄 + 結構化引導）

基於全面的分析和評估，**強烈推薦採用方案二**。主要理由如下：

**解決核心問題的有效性**：
- **召回問題**：即時記錄完全解決了長對話中的資訊遺漏問題，不依賴 AI 事後回顧
- **過度記錄問題**：明確的觸發條件（方向調整、技術障礙、關鍵決策、後續依賴）和「照預期完成留空」的指引，能有效避免不必要的記錄
- **判斷標準**：結構化標籤和具體範例大幅降低判斷的主觀性

**實施可行性**：
- 修改範圍明確：主要在 `commands/process-task-list.md` 的兩個章節
- 與現有流程相容：不破壞既有的 TodoWrite、Git 工作流程
- AI 容易理解：結構化指引和明確範例讓 AI 能快速適應

**使用者體驗**：
- 符合使用者的開放態度：使用者表示「邊做邊記錄也可以」
- 實際上更自然：即時記錄在軟體開發中是常見實踐（如 git commit message、code comments）
- 不會明顯增加執行時間：記錄動作簡短，不會嚴重打斷流程

**可擴展性**：
- 如果未來需要更高品質，可以在此基礎上增加方案三的「精煉」步驟
- 結構化標籤（`[方向調整]` 等）為未來的自動化分析提供可能

### 實施建議

**階段一：核心修改（必要）**

1. 在 `commands/process-task-list.md` 第 92 行「任務實作」章節後，新增「實作過程記錄」指引（詳見方案二完整內容）

2. 修改第 102-107 行的「填寫實作備註」步驟為「檢查並完善實作備註」（詳見方案二）

3. 新增「實作備註品質檢查清單」表格（可放在文件末尾的「TDD 開發流程」章節之前）

**階段二：增強指引（建議）**

4. 在文件中新增「實作備註範例庫」章節，收集更多真實案例：

```markdown
## 實作備註範例庫

### 範例一：API 限制導致的方向調整
**任務**：實作用戶頭像上傳功能
**實作備註**：
```
[方向調整] 原計畫使用 PUT /users/:id/avatar 直接上傳，但發現現有 API 不支援 multipart/form-data。與後端確認後改用兩步驟：POST /upload 取得 URL，然後 PATCH /users/:id 更新 avatar 欄位。
```

### 範例二：效能問題的技術障礙
**任務**：實作筆記搜尋功能
**實作備註**：
```
[技術障礙] 使用簡單的字串 includes() 搜尋，當筆記數量超過 1000 則明顯卡頓。改用 Fuse.js 進行模糊搜尋，測試 5000 筆資料響應時間 < 100ms。
[後續依賴] 已在 package.json 新增 fuse.js 依賴，後續任務若需修改搜尋邏輯請參考 Fuse.js 文件。
```

### 範例三：設計變更的關鍵決策
**任務**：實作狀態管理
**實作備註**：
```
[技術決策] 原 PRD 未明確狀態管理方案。討論 Context API vs Zustand vs Redux 後，選擇 Zustand：(1) 專案規模中小型不需 Redux 複雜度 (2) Zustand 比 Context 效能更好避免不必要 re-render (3) 團隊成員對 Zustand 有經驗。
```

（更多範例...）
```

5. 如果在實際使用中發現某些觸發條件仍不夠明確，可以進一步細化：

```markdown
**觸發條件細化**：

- **方向調整**：
  - ✅ 觸發：原計畫的技術方案無法實現（API 不支援、技術限制）
  - ✅ 觸發：原計畫可行但有重大缺陷（效能問題、安全隱患）
  - ✅ 觸發：與使用者討論後改變實作方式
  - ❌ 不觸發：正常的程式碼重構（如提取函數、改變變數名）
  - ❌ 不觸發：修正小的邏輯錯誤或 typo

- **技術障礙**：
  - ✅ 觸發：第三方 API/函式庫的限制需要繞過
  - ✅ 觸發：效能瓶頸需要特別優化
  - ✅ 觸發：相容性問題需要 polyfill 或替代方案
  - ❌ 不觸發：常見的除錯過程（如修正函數呼叫錯誤）
  - ❌ 不觸發：查文件找到正確的 API 用法（這是正常流程）
```

**階段三：監控與調整（建議）**

6. 在實施後的前幾個專案中，主動檢查實作備註的品質：
   - 是否還有「照預期完成卻寫太多」的情況？
   - 是否還有「重大偏離卻沒記錄」的情況？
   - 標籤使用是否正確（`[方向調整]` vs `[技術障礙]` 等）？

7. 根據實際使用情況，調整：
   - 觸發條件的描述（如果仍有混淆）
   - 範例的數量和質量（增加更貼近實際情況的範例）
   - 標籤的分類（如果四個分類不夠或太多）

### 備選方案

如果實施方案二後發現以下情況，可以考慮調整：

**情況一：即時記錄確實打斷了流程**
- 症狀：AI 在執行任務時因為記錄動作而變得支離破碎
- 解決：回退到方案一（增強回顧機制），但保留方案二的結構化標籤和範例
- 理由：方案一的「引用提取」+ 方案二的「具體範例」組合可能也有效

**情況二：記錄品質仍不穩定**
- 症狀：即時記錄後，備註品質有時好有時差，缺乏一致性
- 解決：升級到方案三（混合式），增加「回顧與精煉」步驟
- 理由：額外的精煉步驟可以確保最終輸出品質，雖然增加複雜度但值得

**情況三：特定類型的偏離仍被遺漏**
- 症狀：某一類偏離（如「驗收時才發現的設計錯誤」）仍經常沒被記錄
- 解決：為該類型增加專門的觸發條件和範例
- 範例：

```markdown
5. **驗收階段發現的設計問題**
   - 觸發條件：執行驗收測試時發現設計不符需求、需要修改先前任務的實作
   - 記錄格式：`[設計修正] 驗收時發現 X 問題，因為 Y，修改為 Z`
   - 範例：`[設計修正] 驗收時發現用戶登出後 localStorage 未清除，導致下次登入帶有舊資料，增加 logout 時的清理邏輯`
```

## 下一步行動計畫

### 立即行動（建議 1-2 天內完成）

1. **修改 process-task-list.md**
   - 在第 92 行後新增「實作過程記錄」指引
   - 修改第 102-107 行為「檢查並完善實作備註」
   - 新增「實作備註品質檢查清單」表格
   - 提交 git commit：`feat: enhance implementation notes with structured real-time logging`

2. **驗證修改**
   - 使用 `/process-task-list` 執行一個簡單任務，觀察 AI 是否按新指引填寫實作備註
   - 測試兩種情況：照預期完成的任務 + 有方向調整的任務
   - 確認指引的清晰度和 AI 的理解程度

### 中期行動（1-2 週內）

3. **收集真實案例**
   - 在實際專案中使用新的機制
   - 記錄至少 5-10 個真實的實作備註案例
   - 分析哪些類型的記錄效果好，哪些還需改進

4. **建立範例庫**（可選）
   - 基於收集的案例，建立「實作備註範例庫」章節
   - 涵蓋各種常見情況（API 限制、效能問題、設計變更等）
   - 為每個範例提供背景脈絡

5. **細化觸發條件**（如需要）
   - 如果發現某些情況仍難以判斷，增加更細緻的說明
   - 更新「觸發條件細化」清單

### 長期優化（1 個月後）

6. **評估效果**
   - 統計實施前後的實作備註品質差異
   - 收集自己或團隊成員的使用回饋
   - 識別仍存在的問題或改進空間

7. **考慮是否需要升級到方案三**
   - 如果即時記錄已經很好，方案二足夠
   - 如果需要更高品質或更簡潔的備註，考慮加入「精煉」步驟

8. **分享經驗**（可選）
   - 將改進過程和結果記錄到專案文件（如 CLAUDE.md）
   - 分享到社群或 GitHub issue，幫助其他使用者

### 風險與應對

**風險一：AI 不按新指引執行**
- 徵兆：實作備註仍然是舊的模式（事後回顧或過度記錄）
- 應對：檢查指引的位置和措辭，確保 AI 在執行時能看到並理解

**風險二：即時記錄影響流程流暢度**
- 徵兆：任務執行變得支離破碎，AI 頻繁被「打斷」
- 應對：調整指引措辭，強調「簡短記錄」而非「詳細描述」，或考慮回退到方案一

**風險三：標籤使用混亂**
- 徵兆：AI 不清楚該用 `[方向調整]` 還是 `[技術障礙]`
- 應對：提供更多對比範例，或簡化標籤分類（如合併為「偏離計畫」和「技術問題」兩類）

## 參考資料

### 技術文件

- **Anthropic - Long context prompting for Claude 2.1**
  https://www.anthropic.com/news/claude-2-1-prompting
  關於 Claude 長文本召回的官方指引，包括 Quote Extraction 和 Contextual Examples 技術

- **Anthropic - Prompt engineering for Claude's long context window**
  https://www.anthropic.com/news/prompting-long-context
  長文本 prompt engineering 的最佳實踐

- **Microsoft - Prompt engineering techniques**
  https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering
  通用 prompt engineering 技術和原則

### 實作範例

- **本專案的實作計畫範例**：
  - `docs/specs/2025-09-19-implementation-context-transfer/implementation.md`
  - `docs/specs/2025-10-30-workflow-context-awareness/implementation.md`
  （雖然實作備註為空，但展示了預期的文件結構）

- **process-task-list.md 當前版本**：
  - `commands/process-task-list.md`
  （完整的任務執行流程和指引）

### 延伸閱讀

- **A developer's guide to prompt engineering and LLMs - GitHub Blog**
  https://github.blog/ai-and-ml/generative-ai/prompt-engineering-guide-generative-ai-llms/
  開發者導向的 prompt engineering 指南

- **Prompt Engineering Guide**
  https://www.promptingguide.ai/
  全面的 prompt engineering 資源和技術合集

- **Best practices for AI-assisted documentation**
  業界對於使用 AI 產生文件的最佳實踐，特別是「即時記錄 vs 事後回顧」的討論
